# 07.06.2020
Начал работу. 

* Скачал файлы `.csv` и сам датасет (32Гб) из фотографий ;
* Сделал скрипт, который многопоточно ресайзит все фотографии в нужное разрешение;
* Сделал скрипт, разбивающий train на фолды, при этом, есть возможность выделять часть выборки как валидационную;
* Сделал класс `MelanomaDataset`, а также нашел корректные аугментации;
* Сделал модель, переделал `MelanomaDataset` и трансформации;

# 08.06.2020
* Первые 5 моделей обучились, процесс обучения лежит в `exp_01.txt`;
* Не смог сделать нормальный инференс, поэтому переобучаю на другом кернеле;
* Запустил обучение на других параметрах;

# 09.06.2020
* Понял, что надо уменьшить `LR`, сделать GroupKFold и добавить TTA;
* Сделал разбитие по GroupKFold (`train_folds_2.csv`);
* Уменьшил `LR`, заменил `AdamW` на `Adam` - результат много хуже, заменяю обратно;
* Ресайзнул изображения до `256x256`;
* Добавил `d4_transform` как TTA (`hflip + rotation [0, 90, 180, 270]`);
* Добавил считывание конфига;
* Добавил отдельный скрипт для обучения;
* Поправил код, исходя из замечаний ревьюера;
* Понял, что надо попробовать `CyclicLR`;
* Третий эксперимент оказался ужасным по скору;
* Осознал, что нужно также разбивать и валидационную выборку групповым методом, исправил код;
* Добавил в код вычисление ROC AUC по hold-out сету;
* Изменил TTA на `hflip + vflip + rotation [0] (исходное)`;
* Сейчас сделаю последнюю попытку с `256x256`, `ReduceLROnPlateau`, изменённой аугментацией, TTA и групповыми фолдами;

# 10.06.2020
* Код упал с ошибкой на вычислении результата на hold-out сете;
* Запустил все эксперименты на hold-out сетах;
* Запустил пятый эксперимент;
* Исследовал таргет, предстазанный для теста: понял, что эксперименты с разрешением `256x256` предсказывают ничтожно мало сэмплов с классом 1: 6 из 10982 - это 0.05%, хотя количество в тесте примерно 1.76%. Посмотрел на второй эксперимент (`512x512`), там уже 0.52% - уже хоть что-то. Далее написал какие эксперименты с этим таргетом хочется провести и как их можно улучшить. См. `Experiments.md`;
* Понял, что надо было использовать FocalLoss;
* Сделал скрипт, выводящий статистику и распределения по предсказанному таргету;
* Пятый эксперимент прошел неуспешно, с классом 1 только 5 сэмплов;
* Начал 6 эксперимент, калька со второго с наилучшим результатом;


# 11.06.2020
* 6 эксперимент показал очень высокий ROC AUC(0.914) на kaggle, на hold-out выборке, но дал всего 9 предсказаний класса 1;
* Запустил 7 эксперимент с стратифицированными фолдами и большей `ES_PATIENCE`;
* Задумался о том, что. возможно, эти модели, которые дают хорошие скоры, просто идельно предсказывают все классы 1, но а остальные, в которых они уверены не настолько, просто относятся к классу 0. Можно попробовать брать для псевдо-лэйблинга вообще все вероятности, начиная от 1, пока не наберётся нужный процент от всей выборки;
