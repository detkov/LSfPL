# Эксперименты  

[x] Посмотреть сколько значений от общего кол-ва лежит в пределах (`show_prediction_stats.py`)
* [0, 0.05]
* [0, 0.10]
* [0, 0.15]
* [0, 0.20]
* [0.80, 1]
* [0.85, 1]
* [0.90, 1]
* [0.95, 1]

## Идеи для обучения и инференса моделей
* [x] Попробовать как обучение всей сети, так и только последнего слоя, или 2 последних слоёв (если также есть пулинг);
* [x] Попробовать усреднить веса до и после fine-tuning'а; (не получилось)


## Генерация экспериментов
Как сгенерировать различные экспериментальные pseudo labels из имеющего `exp_train_02.csv` и идей? Ответ по пунктам:
1) [x] Сделать under-sampling: 
   * Рандомный (`rnd_undspml.csv`)
   * Стратифицированный по бинам `target` (`[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.1]`) (`str_undspml.csv`)
   
   Присобачить к ним `test.csv` для дальнейшей работы.  
   Результат - 2 датафрейма формата `submission.csv`, но с разными строками и фичами из теста и с фичей `target_class` (`0 if p<=0.5 else 1`);
2) [x] Взять для недопреставленного класса разделение не > 0.5, а набирать его, пока не наберётся распределение, близкое к трейну. Поставить метки о принадлежности к классу `target_class`.  
Результат - датафрейма формата `submission.csv`, но с фичами из теста и с фичей `target_class`;
3) [x] Применить label-smoothing:
   * Взять `[50, 80, 100]`% всех предсказаний с наибольшей уверенностью по каждому из классов отдельно
      * Далее применить к вероятностям, исходя из `target_class`:
         * Оставить как есть                     (код 1)
         * Гладкое округление до 0.10 или 0.90   (код 2)
         * Гладкое округление до 0.05 или 0.95   (код 3)
         * Гладкое округление до 0.05 или 1.00   (код 4)
         * Гладкое округление до 0.10 или 1.00   (код 5)
         * Гладкое округление до 0.20 или 1.00   (код 6)
   
      Для каждого `pct` из `[50, 80, 100]`.
   
   Применить для каждого датафрейма, полученного в п.1 и п.2;
4) [x] Применить ко всем полученным `.csv` экспериментам стратифицированное разбитие на фолды;

Итого, 3 * 3 * 6 = 54 - 3 (когда 100 и 1) = 51 эксперимент.  
Если учитывать п.1 из "Идеи для обучения и инференса моделей", то 51 * 2 = 102. Для п.2 же, новые эксперименты не нужны.
