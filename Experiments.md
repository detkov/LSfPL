# Эксперименты
* Посмотреть сколько значений от общего кол-ва лежит в пределах
  * [0, 0.05)
  * [0, 0.10)
  * [0, 0.15)
  * [0, 0.20)
  * (0.80, 1]
  * (0.85, 1]
  * (0.90, 1]
  * (0.95, 1]

Список экспериментов, которые хочется провести с pseudo-labeled данными:

Дообучиться N эпох с изначальным LR, равным последнему LR во время обучения (усреднить для всех фолдов), взяв 
1) По [50, 60, 70, 80]% всех предсказаний с наибольшей уверенностью по отношению к классу 0 и 1 (отдельно). Но таким образом, если распределение таргета теста не равно распределению таргету трейна, то это может ухудшить результат;
2) Предсказания после перебалансировки количества сэплов в каждом из классов. То есть, если распределение таргета теста не равно распределению таргета трейна, мы доводим его до него: убираем из превалирующего класса достаточное количество сэмплов, чтобы распределения были максимально одинаковыми. Можно убирать сэмплы
   1) либо случайным образом = рандомный under-sampling;
   2) либо сохраняя распределение таргета по бинам = стратифицированный under-sampling.
3) Предсказания, пользуясь алгоритмами из п.2, а далее из п.1. 



Дополнительные идеи:
* Можно попробовать как обучение всей сети, так и только последнего слоя, или 2 последних слоёв (если также есть пулинг)
* Можно попробовать усреднить веса до и после fine-tuning'а
* 