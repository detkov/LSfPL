# Эксперименты
## [x] Посмотреть сколько значений от общего кол-ва лежит в пределах (`show_prediction_stats.py`)
* [0, 0.05]
* [0, 0.10]
* [0, 0.15]
* [0, 0.20]
* [0.80, 1]
* [0.85, 1]
* [0.90, 1]
* [0.95, 1]

## Идеи для обучения и инференса моделей
* [ ] Можно попробовать как обучение всей сети, так и только последнего слоя, или 2 последних слоёв (если также есть пулинг)
* [ ] Можно попробовать усреднить веса до и после fine-tuning'а


## Генерация экспериментов
Как сгенерировать различные экспериментальные pseudo-labels из имеющего `exp_train_02.csv` и идей? Ответ по пунктам:
1) [x] Сделать under-sampling: 
   * Рандомный (`rnd_undspml.csv`)
   * Стратифицированный по бинам `target` (`[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.1]`) (`str_undspml.csv`)
   
   [x] Присобачить к ним `test.csv` для дальнейшей работы.  
   [x] Результат - 2 датафрейма формата `submission.csv`, но с разными строками и фичами из теста и с фичей `target_class` (`0 if p<0.5 else 1`);
2) [x] Взять для недопреставленного класса разделение не >= 0.5, а набирать его, пока не наберётся распределение, близкое к трейну. Поставить метки о принадлежности к классу.  
Результат - датафрейма формата `submission.csv`, но с фичами из теста и с фичей `target_class`.
3) Применить label-smoothing:
   * Взять `[50, 80, 90, 100]`% всех предсказаний с наибольшей уверенностью по каждому из классов отдельно
      * Далее применить к вероятностям:
         * Ничего не применять - оставить как есть     (код 1)
         * Округление до 0 или 1 (`0 if p<0.5 else 1`) (код 2)
         * Гладкое округление до 0.10 или 0.90         (код 3)
         * Гладкое округление до 0.05 или 0.95         (код 4)
         * Гладкое округление до 0.05 или 1.00         (код 5)
         * Гладкое округление до 0.10 или 1.00         (код 6)
         * Гладкое округление до 0.20 или 1.00         (код 7)
         * Гладкое округление до 0.30 или 1.00         (код 8)

      Для каждого `pct` из `[50, 80, 90, 100]`.
   
   Применить для каждого датафрейма, полученного в п.1 и п.2;


Итого, 3 * 4 * 8 = 96 экспериментов.  
Если учитывать п.1 из "Идеи для обучения и инференса моделей", то 96 * 2 = 192. Для п.2 же, новые эксперименты не нужны.  
